{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aswathy7576/NLP-Sarcasm-sentiment-Prediction-LDA-LSA/blob/main/LSA_%26_LDA_Classifiar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peoplealsoask"
      ],
      "metadata": {
        "id": "4g_-smdVcMEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OlsU9h5VjOr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v6znX_SzjWn",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, preprocess_string, strip_short, stem_text\n",
        "from gensim import corpora\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MJZBOl6XxG4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "df=pd.read_json(\"/content/drive/MyDrive/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
        "df.dropna(inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IBw3wnVfzr5n",
        "outputId": "ff708f48-f41c-4ca6-d7fe-fadd688ebf82",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        article_link  \\\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
              "2  https://local.theonion.com/mom-starting-to-fea...   \n",
              "3  https://politics.theonion.com/boehner-just-wan...   \n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
              "\n",
              "                                            headline  is_sarcastic  \n",
              "0  former versace store clerk sues over secret 'b...             0  \n",
              "1  the 'roseanne' revival catches up to our thorn...             0  \n",
              "2  mom starting to fear son's web series closest ...             1  \n",
              "3  boehner just wants wife to listen, not come up...             1  \n",
              "4  j.k. rowling wishes snape happy birthday in th...             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34f649f7-6cc8-49ce-8c03-8f76dde95280\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34f649f7-6cc8-49ce-8c03-8f76dde95280')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34f649f7-6cc8-49ce-8c03-8f76dde95280 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34f649f7-6cc8-49ce-8c03-8f76dde95280');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**RandomForestClassifier model for Classification**"
      ],
      "metadata": {
        "id": "AE9W4Apkwsct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.headline\n",
        "y = df.is_sarcastic\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
        "print(\"Train set has total {0} entries with {1:.2f}% Not Sarcasm, {2:.2f}% Sarcasm\".format(len(X_train),\n",
        "                                                                             (len(X_train[y_train == 0]) / (len(X_train)*1.))*100,\n",
        "                                                                            (len(X_train[y_train == 1]) / (len(X_train)*1.))*100))\n",
        "\n",
        "print(\"Test set has total {0} entries with {1:.2f}% Not Sarcasm, {2:.2f}% Sarcasm\".format(len(X_test),\n",
        "                                                                             (len(X_test[y_test == 0]) / (len(X_test)*1.))*100,\n",
        "                                                                            (len(X_test[y_test == 1]) / (len(X_test)*1.))*100))\n",
        "\n",
        "# model trainer\n",
        "cv = CountVectorizer()\n",
        "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
        "n_features = np.arange(10000,30001,10000)\n",
        "# set pipeline\n",
        "def accuracy_summary(pipeline, X_train, y_train, X_test, y_test):\n",
        "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
        "    y_pred = sentiment_fit.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
        "    return accuracy\n",
        "def nfeature_accuracy_checker(vectorizer=cv, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=rf):\n",
        "    result = []\n",
        "    print(classifier)\n",
        "    print(\"\\n\")\n",
        "    for n in n_features:\n",
        "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
        "        checker_pipeline = Pipeline([\n",
        "            ('vectorizer', vectorizer),\n",
        "            ('classifier', classifier)\n",
        "        ])\n",
        "        print(\"Test result for {} features\".format(n))\n",
        "        nfeature_accuracy = accuracy_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n",
        "        result.append((n,nfeature_accuracy))\n",
        "    return result\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "print(\"Result for trigram with stop words (Tfidf)\\n\")\n",
        "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tfidf,ngram_range=(1, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOO1-afq3IKm",
        "outputId": "3cbda180-74b0-4c15-ef13-11e64f508688",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set has total 20031 entries with 56.14% Not Sarcasm, 43.86% Sarcasm\n",
            "Test set has total 6678 entries with 55.99% Not Sarcasm, 44.01% Sarcasm\n",
            "Result for trigram with stop words (Tfidf)\n",
            "\n",
            "RandomForestClassifier(class_weight='balanced')\n",
            "\n",
            "\n",
            "Test result for 10000 features\n",
            "accuracy score: 81.22%\n",
            "Test result for 20000 features\n",
            "accuracy score: 81.19%\n",
            "Test result for 30000 features\n",
            "accuracy score: 81.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(max_features=30000,ngram_range=(1, 3))\n",
        "pipeline = Pipeline([\n",
        "        ('vectorizer', cv),\n",
        "        ('classifier', rf)\n",
        "    ])\n",
        "sentiment_fit = pipeline.fit(X_train, y_train)\n",
        "y_pred = sentiment_fit.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=['Not Sarcasm','Sarcasm']))"
      ],
      "metadata": {
        "id": "KhhNk71k451u",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec1abc2-7209-4729-9dfe-0b267f0afb2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " Not Sarcasm       0.86      0.80      0.83      3739\n",
            "     Sarcasm       0.77      0.83      0.80      2939\n",
            "\n",
            "    accuracy                           0.81      6678\n",
            "   macro avg       0.81      0.82      0.81      6678\n",
            "weighted avg       0.82      0.81      0.81      6678\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**LSA Model for topic_modeling**"
      ],
      "metadata": {
        "id": "x4RumKQRviXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess given text\n",
        "def preprocess(text):\n",
        "\n",
        "    # clean text based on given filters\n",
        "    CUSTOM_FILTERS = [lambda x: x.lower(),\n",
        "                                remove_stopwords,\n",
        "                                strip_short,\n",
        "                                stem_text]\n",
        "    text = preprocess_string(text, CUSTOM_FILTERS)\n",
        "\n",
        "    return text\n",
        "\n",
        "from gensim.models import LsiModel\n",
        "# topic finding\n",
        "def find_topic(data):\n",
        "  df=pd.DataFrame({\"text\":data})\n",
        "  # apply function to all reviews\n",
        "  data = df[\"text\"].apply(lambda x: preprocess(x))\n",
        "\n",
        "  # create a dictionary with the corpus\n",
        "  dictionary = corpora.Dictionary(data)\n",
        "\n",
        "  # convert corpus into a bag of words\n",
        "  bow = [dictionary.doc2bow(text) for text in data]\n",
        "\n",
        "  # find the coherence score with a different number of topics\n",
        "  for i in range(2,11):\n",
        "      lsi = LsiModel(bow, num_topics=i, id2word=dictionary)\n",
        "      coherence_model = CoherenceModel(model=lsi, texts=data, dictionary=dictionary, coherence='c_v')\n",
        "      coherence_score = coherence_model.get_coherence()\n",
        "\n",
        "  # perform SVD on the bag of words with the LsiModel to extract 2 topics\n",
        "  lsi = LsiModel(bow, num_topics=2, id2word=dictionary)\n",
        "  x=\" \".join(map(str,re.findall(\"[A-Za-z]+\",lsi.print_topics(num_words=7)[0][1])))\n",
        "  return x"
      ],
      "metadata": {
        "cellView": "code",
        "id": "VWJfOAADvhAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Prediction Function for LSA**"
      ],
      "metadata": {
        "id": "q8SdDWByYjrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Prediction_Function(Text):\n",
        "  y_pred = sentiment_fit.predict([Text])\n",
        "\n",
        "  if y_pred==0:\n",
        "    print(\"This is not sarcasm Using LSA the topic is: \"+find_topic([Text]))\n",
        "  else:\n",
        "    print(\"This is sarcasm Using LSA and the topic is: \"+find_topic([Text]))\n",
        "\n",
        "Prediction_Function(\"The teaser for upcoming drama Wehshi, starring Khushhal Khan as boy-turned-brute Asif, is out\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wcf3hcOKVvs9",
        "outputId": "6091952d-f208-4a2e-9d37-f042ab13113a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is not sarcasm Using LSA the topic is: asif teaser upcom khushhal boy turned brut khan wehshi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LDA Model For topic_modeling**"
      ],
      "metadata": {
        "id": "BWxxGhDUvFwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def extract_topic(text,n_top_words):\n",
        "  q=(text,)\n",
        "  value={}\n",
        "  lda = LatentDirichletAllocation(n_components=10, max_iter=5,\n",
        "                                learning_method='online',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0)\n",
        "  tf_vectorizer = CountVectorizer(\n",
        "                                max_features=50,\n",
        "                                stop_words='english')\n",
        "  tf = tf_vectorizer.fit_transform(q)\n",
        "  tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "  lda.fit(tf)\n",
        "\n",
        "  for topic_idx, topic in enumerate(lda.components_):\n",
        "        count=topic_idx\n",
        "        x=\" \".join([tf_feature_names[i]\n",
        "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        value.update({count:x})\n",
        "\n",
        "  return value"
      ],
      "metadata": {
        "id": "iGX--IQovEb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Prediction Function for LDA**"
      ],
      "metadata": {
        "id": "BEv8IN8HwP-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Prediction_Function(Text):\n",
        "  y_pred = sentiment_fit.predict([Text])\n",
        "\n",
        "  if y_pred==0:\n",
        "    print(\"This is not sarcasm Using LDA and the Topic is: \"+extract_topic(Text,5)[0])\n",
        "  else:\n",
        "    print(\"This is sarcasm Using LDA and the Topic is: \"+extract_topic(Text,5)[0])\n",
        "\n",
        "Prediction_Function(\"The teaser for upcoming drama Wehshi, starring Khushhal Khan as boy-turned-brute Asif, is out\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TBrxMGiuyqx",
        "outputId": "c2a064ff-da62-4223-cee8-009d442e8e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is not sarcasm Using LDA and the Topic is: brute asif wehshi starring turned\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(Text):\n",
        "  y_pred = sentiment_fit.predict([Text])\n",
        "\n",
        "  if y_pred==0:\n",
        "    return (\"This is not sarcasm\"+ \"\\n\\nUsing LSA the topic is: \"+find_topic([Text])+ \" \\n\\nUsing LDA and the Topic is: \"+extract_topic(Text,7)[0])\n",
        "  else:\n",
        "    return (\"This is sarcasm\"+ \"\\n\\nUsing LSA and the topic is: \"+find_topic([Text])+ \" \\n\\nUsing LDA and the Topic is: \"+extract_topic(Text,7)[0])\n",
        "\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\",title=\"Topic Modeling & Classification\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "7QL3AduSZYvZ",
        "outputId": "60bb807a-1e85-440c-cafb-3520e90d4ebc",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://23839.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://23839.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f359c264350>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://23839.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#THE_END"
      ],
      "metadata": {
        "id": "neAvtVzEZgsB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}